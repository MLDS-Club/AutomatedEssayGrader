{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Import other functions\n",
    "from process.averageWordLength import averageWordLength\n",
    "from process.misspellings import nmisspelled\n",
    "from process.wordcount import length\n",
    "from process.averageSentenceLength import averageSentenceLength\n",
    "from process.grammarchecker import grammarCheck\n",
    "from process.keywords import keyWords\n",
    "from process.sentcount import sentcount\n",
    "from process.vocabulary import VocabCounter\n",
    "from process.stopwords import stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean essays\n",
    "df = pd.read_feather('data/essays.feather')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['cleaned_essay'] = df['essay'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing filler words\n",
    "def filler(word):\n",
    "    if (word.isupper() == True) and (any([char.isdigit() for char in word])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df['cleaned_essay2'] = df['cleaned_essay'].apply(lambda i : [x for x in i if not filler(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        [Dear, local, newspaper, think, effects, compu...\n",
       "1        [Dear, believe, using, computers, benefit, us,...\n",
       "2        [Dear, people, use, computers, everyone, agree...\n",
       "3        [Dear, Local, Newspaper, found, many, experts,...\n",
       "4        [Dear, know, computers, positive, effect, peop...\n",
       "                               ...                        \n",
       "12971    [stories, mothers, daughters, either, enemies,...\n",
       "12972    [never, understood, meaning, laughter, shortes...\n",
       "12973    [laugh, habit, cause, causes, laughing, even, ...\n",
       "12974    [Trippin, fences, years, young, short, years, ...\n",
       "12975    [Many, people, believe, laughter, improve, lif...\n",
       "Name: cleaned_essay2_no_sw, Length: 12976, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['cleaned_essay2_no_sw'] = df['cleaned_essay2'].apply(lambda x : [w for w in x if not w.lower() in stop_words])\n",
    "\n",
    "df['cleaned_essay2_no_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        67.0\n",
       "1        75.0\n",
       "2        58.0\n",
       "3        83.0\n",
       "4        67.0\n",
       "         ... \n",
       "12971    58.0\n",
       "12972    53.0\n",
       "12973    67.0\n",
       "12974    67.0\n",
       "12975    67.0\n",
       "Name: normalized_score, Length: 12976, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Setting the prompts and normalizing the scores\n",
    "\n",
    "def prompt(essay_set):\n",
    "    if essay_set == 1:\n",
    "        return \"Write a letter to your local newspaper in which you state your opinion on the effects computers have on people\"\n",
    "    elif essay_set == 2:\n",
    "        return \"Write a persuasive essay to a newspaper reflecting your vies on censorship in libraries. Do you believe that certain materials, such as books, music, movies, magazines, etc., should be removed from the shelves if they are found offensive?\"\n",
    "    elif essay_set == 3:\n",
    "        return \"Write a response that explains how the features of the setting affect the cyclist\"\n",
    "    elif essay_set == 4:\n",
    "        return \"Write a response that explains why the author concludes the story with this paragraph\"\n",
    "    elif essay_set == 5:\n",
    "        return \"Describe the mood created by the author in the memoir\"\n",
    "    elif essay_set == 6:\n",
    "        return \"Based on the excerpt, describe the obstacles the builders of the Empire State Building faced in attempting to allow dirigibles to dock there\"\n",
    "    elif essay_set == 7:\n",
    "        return \"Do only one of the following: write a story about a time when you were patient OR write a story about a time when someone you know was patient OR write a story in your own way about patience\"\n",
    "    elif essay_set == 8:\n",
    "        return \"Tell a true story in which laughter was one element or part\"\n",
    "\n",
    "df['prompt'] = df['essay_set'].apply(prompt)\n",
    "\n",
    "def normalizeScores(essay_set, score):\n",
    "    if essay_set == 1:\n",
    "        return round((score/12), 2)*100\n",
    "    elif essay_set == 2:\n",
    "        return round((score/6), 2)*100\n",
    "    elif essay_set == 3:\n",
    "        return round((score/3), 2)*100\n",
    "    elif essay_set == 4:\n",
    "        return round((score/3), 2)*100\n",
    "    elif essay_set == 5:\n",
    "        return round((score/4), 2)*100\n",
    "    elif essay_set == 6:\n",
    "        return round((score/4), 2)*100\n",
    "    elif essay_set == 7:\n",
    "        return round((score/30), 2)*100\n",
    "    elif essay_set == 8:\n",
    "        return round((score/60), 2)*100\n",
    "    \n",
    "df['normalized_score'] = df.apply(lambda x : normalizeScores(x.essay_set, x.domain1_score), axis=1)\n",
    "df['normalized_score']"
   ]
  },
  {
   "source": [
    "Making features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new features\n",
    "\n",
    "# Average word length\n",
    "df['Average Word Length'] = df['cleaned_essay2'].apply(averageWordLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of misspellings\n",
    "df['misspelled'] = df['cleaned_essay2'].apply(nmisspelled)"
   ]
  },
  {
   "source": [
    "# word count\n",
    "def length(essay):\n",
    "    return len(essay)\n",
    "df['word_count'] = df['cleaned_essay2'].apply(length)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentence length\n",
    "df['average_sentence_length'] = df['essay'].apply(averageSentenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------Need to find a faster grammar checker-------\n",
    "# df['grammar_errors'] = df['essay'].apply(grammarCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         4.97\n",
       "1         5.14\n",
       "2        13.18\n",
       "3         8.05\n",
       "4         6.36\n",
       "         ...  \n",
       "12971     2.49\n",
       "12972     2.06\n",
       "12973     1.46\n",
       "12974     2.60\n",
       "12975     0.47\n",
       "Name: key_words_count, Length: 12976, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# percentage of essay that uses key words\n",
    "df['key_words_count'] = df.apply(lambda x: keyWords(x.prompt, x.cleaned_essay2_no_sw), axis=1)\n",
    "df['key_words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence count\n",
    "df['sentcount'] = df['essay'].apply(sentcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        0.87\n",
       "1        1.69\n",
       "2        1.09\n",
       "3        1.02\n",
       "4        0.85\n",
       "         ... \n",
       "12971    1.49\n",
       "12972    0.38\n",
       "12973    0.77\n",
       "12974    1.44\n",
       "12975    1.08\n",
       "Name: vocabulary, Length: 12976, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# vocabulary words\n",
    "def vocabulary(li):\n",
    "    vocab = VocabCounter()\n",
    "    return round(vocab.CountVocab(li)*100, 2)\n",
    "df['vocabulary'] = df['cleaned_essay2'].apply(vocabulary)\n",
    "df['vocabulary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'cleaned_essay',\n",
       "       'Average Word Length', 'score'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# score to quantify imagery/effective word choice of each essay\n",
    "imagery = pd.read_feather('imagery.feather')\n",
    "imagery.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'cleaned_essay',\n",
       "       'cleaned_essay_no_sw', 'cleaned_essay2', 'cleaned_essay2_no_sw',\n",
       "       'Average Word Length', 'misspelled', 'word_count',\n",
       "       'average_sentence_length', 'prompt', 'normalized_score',\n",
       "       'key_words_count', 'sentcount', 'vocabulary', 'score'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df2 = pd.concat([df, imagery['score']], axis=1)\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        53.33\n",
       "1        48.18\n",
       "2        53.26\n",
       "3        46.63\n",
       "4        53.09\n",
       "         ...  \n",
       "12971    55.20\n",
       "12972    53.89\n",
       "12973    55.91\n",
       "12974    58.45\n",
       "12975    54.21\n",
       "Name: percent_stop_words, Length: 12976, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Percent stop words\n",
    "df2['percent_stop_words'] = df['cleaned_essay2'].apply(stopWords)\n",
    "df2['percent_stop_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'cleaned_essay',\n",
       "       'cleaned_essay_no_sw', 'cleaned_essay2', 'cleaned_essay2_no_sw',\n",
       "       'Average Word Length', 'misspelled', 'word_count',\n",
       "       'average_sentence_length', 'prompt', 'normalized_score',\n",
       "       'key_words_count', 'sentcount', 'vocabulary', 'score',\n",
       "       'percent_stop_words', 'grade'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Making grade column - (0 is middle school, 1 is high school)\n",
    "def grade(essay_set):\n",
    "    if (essay_set == 1) or (essay_set == 5) or (essay_set == 7):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df2['grade'] = df2['essay_set'].apply(grade)\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'cleaned_essay',\n",
       "       'cleaned_essay_no_sw', 'cleaned_essay2', 'cleaned_essay2_no_sw',\n",
       "       'Average Word Length', 'misspelled', 'word_count',\n",
       "       'average_sentence_length', 'prompt', 'normalized_score',\n",
       "       'key_words_count', 'sentcount', 'vocabulary', 'score',\n",
       "       'percent_stop_words', 'grade', 'Source Dependent Responses',\n",
       "       'Persuasive/Narrative/Expository'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Making topic column\n",
    "def source(essay_set):\n",
    "    if (essay_set == 1) or (essay_set == 2) or (essay_set == 7) or (essay_set == 8):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def pne(essay_set):\n",
    "    if (essay_set == 3) or (essay_set == 4) or (essay_set == 5) or (essay_set == 6):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df2['Source Dependent Responses'] = df2['essay_set'].apply(source)\n",
    "df2['Persuasive/Narrative/Expository'] = df2['essay_set'].apply(pne)\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       essay_id  essay_set  grade  Source Dependent Responses  \\\n",
       "0             1          1      0                           1   \n",
       "1             2          1      0                           1   \n",
       "2             3          1      0                           1   \n",
       "3             4          1      0                           1   \n",
       "4             5          1      0                           1   \n",
       "...         ...        ...    ...                         ...   \n",
       "12971     21626          8      1                           1   \n",
       "12972     21628          8      1                           1   \n",
       "12973     21629          8      1                           1   \n",
       "12974     21630          8      1                           1   \n",
       "12975     21633          8      1                           1   \n",
       "\n",
       "       Persuasive/Narrative/Expository  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "...                                ...   \n",
       "12971                                0   \n",
       "12972                                0   \n",
       "12973                                0   \n",
       "12974                                0   \n",
       "12975                                0   \n",
       "\n",
       "                                                   essay  \\\n",
       "0      Dear local newspaper, I think effects computer...   \n",
       "1      Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2      Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3      Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4      Dear @LOCATION1, I know having computers has a...   \n",
       "...                                                  ...   \n",
       "12971   In most stories mothers and daughters are eit...   \n",
       "12972   I never understood the meaning laughter is th...   \n",
       "12973  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974                                 Trippin' on fen...   \n",
       "12975   Many people believe that laughter can improve...   \n",
       "\n",
       "                                          cleaned_essay2  \\\n",
       "0      [Dear, local, newspaper, I, think, effects, co...   \n",
       "1      [Dear, I, believe, that, using, computers, wil...   \n",
       "2      [Dear, More, and, more, people, use, computers...   \n",
       "3      [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4      [Dear, I, know, having, computers, has, a, pos...   \n",
       "...                                                  ...   \n",
       "12971  [In, most, stories, mothers, and, daughters, a...   \n",
       "12972  [I, never, understood, the, meaning, laughter,...   \n",
       "12973  [When, you, laugh, is, out, of, habit, or, is,...   \n",
       "12974  [Trippin, on, fences, I, am, years, young, and...   \n",
       "12975  [Many, people, believe, that, laughter, can, i...   \n",
       "\n",
       "                                    cleaned_essay2_no_sw  \\\n",
       "0      [Dear, local, newspaper, think, effects, compu...   \n",
       "1      [Dear, believe, using, computers, benefit, us,...   \n",
       "2      [Dear, people, use, computers, everyone, agree...   \n",
       "3      [Dear, Local, Newspaper, found, many, experts,...   \n",
       "4      [Dear, know, computers, positive, effect, peop...   \n",
       "...                                                  ...   \n",
       "12971  [stories, mothers, daughters, either, enemies,...   \n",
       "12972  [never, understood, meaning, laughter, shortes...   \n",
       "12973  [laugh, habit, cause, causes, laughing, even, ...   \n",
       "12974  [Trippin, fences, years, young, short, years, ...   \n",
       "12975  [Many, people, believe, laughter, improve, lif...   \n",
       "\n",
       "                                                  prompt  Average Word Length  \\\n",
       "0      Write a letter to your local newspaper in whic...             4.179710   \n",
       "1      Write a letter to your local newspaper in whic...             4.273608   \n",
       "2      Write a letter to your local newspaper in whic...             4.293478   \n",
       "3      Write a letter to your local newspaper in whic...             4.652352   \n",
       "4      Write a letter to your local newspaper in whic...             4.313433   \n",
       "...                                                  ...                  ...   \n",
       "12971  Tell a true story in which laughter was one el...             3.858911   \n",
       "12972  Tell a true story in which laughter was one el...             3.740038   \n",
       "12973  Tell a true story in which laughter was one el...             4.158098   \n",
       "12974  Tell a true story in which laughter was one el...             3.922662   \n",
       "12975  Tell a true story in which laughter was one el...             4.101512   \n",
       "\n",
       "       misspelled  word_count  average_sentence_length  key_words_count  \\\n",
       "0              11         345                33.800000             4.97   \n",
       "1              16         413                23.277778             5.14   \n",
       "2               2         276                19.928571            13.18   \n",
       "3              24         489                22.782609             8.05   \n",
       "4              13         469                15.500000             6.36   \n",
       "...           ...         ...                      ...              ...   \n",
       "12971           1         808                38.545455             2.49   \n",
       "12972           5         527                26.095238             2.06   \n",
       "12973           7         778                31.461538             1.46   \n",
       "12974           3         556                16.054054             2.60   \n",
       "12975           1         463                16.137931             0.47   \n",
       "\n",
       "       sentcount  vocabulary       score  percent_stop_words  normalized_score  \n",
       "0             10        0.87  142.767857               53.33              67.0  \n",
       "1             18        1.69  195.047857               48.18              75.0  \n",
       "2             14        1.09  134.204429               53.26              58.0  \n",
       "3             23        1.02  236.191000               46.63              83.0  \n",
       "4             30        0.85  178.948286               53.09              67.0  \n",
       "...          ...         ...         ...                 ...               ...  \n",
       "12971         22        1.49  314.048286               55.20              58.0  \n",
       "12972         21        0.38  213.163714               53.89              53.0  \n",
       "12973         26        0.77  209.613286               55.91              67.0  \n",
       "12974         37        1.44  174.643286               58.45              67.0  \n",
       "12975         29        1.08  182.430000               54.21              67.0  \n",
       "\n",
       "[12976 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>essay_set</th>\n      <th>grade</th>\n      <th>Source Dependent Responses</th>\n      <th>Persuasive/Narrative/Expository</th>\n      <th>essay</th>\n      <th>cleaned_essay2</th>\n      <th>cleaned_essay2_no_sw</th>\n      <th>prompt</th>\n      <th>Average Word Length</th>\n      <th>misspelled</th>\n      <th>word_count</th>\n      <th>average_sentence_length</th>\n      <th>key_words_count</th>\n      <th>sentcount</th>\n      <th>vocabulary</th>\n      <th>score</th>\n      <th>percent_stop_words</th>\n      <th>normalized_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Dear local newspaper, I think effects computer...</td>\n      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n      <td>[Dear, local, newspaper, think, effects, compu...</td>\n      <td>Write a letter to your local newspaper in whic...</td>\n      <td>4.179710</td>\n      <td>11</td>\n      <td>345</td>\n      <td>33.800000</td>\n      <td>4.97</td>\n      <td>10</td>\n      <td>0.87</td>\n      <td>142.767857</td>\n      <td>53.33</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n      <td>[Dear, I, believe, that, using, computers, wil...</td>\n      <td>[Dear, believe, using, computers, benefit, us,...</td>\n      <td>Write a letter to your local newspaper in whic...</td>\n      <td>4.273608</td>\n      <td>16</td>\n      <td>413</td>\n      <td>23.277778</td>\n      <td>5.14</td>\n      <td>18</td>\n      <td>1.69</td>\n      <td>195.047857</td>\n      <td>48.18</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n      <td>[Dear, More, and, more, people, use, computers...</td>\n      <td>[Dear, people, use, computers, everyone, agree...</td>\n      <td>Write a letter to your local newspaper in whic...</td>\n      <td>4.293478</td>\n      <td>2</td>\n      <td>276</td>\n      <td>19.928571</td>\n      <td>13.18</td>\n      <td>14</td>\n      <td>1.09</td>\n      <td>134.204429</td>\n      <td>53.26</td>\n      <td>58.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n      <td>[Dear, Local, Newspaper, found, many, experts,...</td>\n      <td>Write a letter to your local newspaper in whic...</td>\n      <td>4.652352</td>\n      <td>24</td>\n      <td>489</td>\n      <td>22.782609</td>\n      <td>8.05</td>\n      <td>23</td>\n      <td>1.02</td>\n      <td>236.191000</td>\n      <td>46.63</td>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Dear @LOCATION1, I know having computers has a...</td>\n      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n      <td>[Dear, know, computers, positive, effect, peop...</td>\n      <td>Write a letter to your local newspaper in whic...</td>\n      <td>4.313433</td>\n      <td>13</td>\n      <td>469</td>\n      <td>15.500000</td>\n      <td>6.36</td>\n      <td>30</td>\n      <td>0.85</td>\n      <td>178.948286</td>\n      <td>53.09</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12971</th>\n      <td>21626</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>In most stories mothers and daughters are eit...</td>\n      <td>[In, most, stories, mothers, and, daughters, a...</td>\n      <td>[stories, mothers, daughters, either, enemies,...</td>\n      <td>Tell a true story in which laughter was one el...</td>\n      <td>3.858911</td>\n      <td>1</td>\n      <td>808</td>\n      <td>38.545455</td>\n      <td>2.49</td>\n      <td>22</td>\n      <td>1.49</td>\n      <td>314.048286</td>\n      <td>55.20</td>\n      <td>58.0</td>\n    </tr>\n    <tr>\n      <th>12972</th>\n      <td>21628</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>I never understood the meaning laughter is th...</td>\n      <td>[I, never, understood, the, meaning, laughter,...</td>\n      <td>[never, understood, meaning, laughter, shortes...</td>\n      <td>Tell a true story in which laughter was one el...</td>\n      <td>3.740038</td>\n      <td>5</td>\n      <td>527</td>\n      <td>26.095238</td>\n      <td>2.06</td>\n      <td>21</td>\n      <td>0.38</td>\n      <td>213.163714</td>\n      <td>53.89</td>\n      <td>53.0</td>\n    </tr>\n    <tr>\n      <th>12973</th>\n      <td>21629</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n      <td>[When, you, laugh, is, out, of, habit, or, is,...</td>\n      <td>[laugh, habit, cause, causes, laughing, even, ...</td>\n      <td>Tell a true story in which laughter was one el...</td>\n      <td>4.158098</td>\n      <td>7</td>\n      <td>778</td>\n      <td>31.461538</td>\n      <td>1.46</td>\n      <td>26</td>\n      <td>0.77</td>\n      <td>209.613286</td>\n      <td>55.91</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>12974</th>\n      <td>21630</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Trippin' on fen...</td>\n      <td>[Trippin, on, fences, I, am, years, young, and...</td>\n      <td>[Trippin, fences, years, young, short, years, ...</td>\n      <td>Tell a true story in which laughter was one el...</td>\n      <td>3.922662</td>\n      <td>3</td>\n      <td>556</td>\n      <td>16.054054</td>\n      <td>2.60</td>\n      <td>37</td>\n      <td>1.44</td>\n      <td>174.643286</td>\n      <td>58.45</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>12975</th>\n      <td>21633</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Many people believe that laughter can improve...</td>\n      <td>[Many, people, believe, that, laughter, can, i...</td>\n      <td>[Many, people, believe, laughter, improve, lif...</td>\n      <td>Tell a true story in which laughter was one el...</td>\n      <td>4.101512</td>\n      <td>1</td>\n      <td>463</td>\n      <td>16.137931</td>\n      <td>0.47</td>\n      <td>29</td>\n      <td>1.08</td>\n      <td>182.430000</td>\n      <td>54.21</td>\n      <td>67.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12976 rows × 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# new dataset\n",
    "data = df2[['essay_id', 'essay_set', 'grade', 'Source Dependent Responses', 'Persuasive/Narrative/Expository', 'essay', 'cleaned_essay2', 'cleaned_essay2_no_sw','prompt', 'Average Word Length', 'misspelled', 'word_count', 'average_sentence_length', 'key_words_count', 'sentcount', 'vocabulary', 'score', 'percent_stop_words', 'normalized_score']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset to feather\n",
    "data.to_feather('dataset.feather')"
   ]
  },
  {
   "source": [
    "Test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the test set (still needs to be done)\n",
    "\n",
    "test = pd.read_csv('~/Documents/GitHub/AutomatedEssayGrader/essaygrader/data/test_set.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "test.to_feather('data/test_set.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_feather('~/Documents/GitHub/AutomatedEssayGrader/essaygrader/data/test_set.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'domain1_predictionid',\n",
       "       'domain2_predictionid'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean essays\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "test['cleaned_essay'] = test['essay'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  }
 ]
}