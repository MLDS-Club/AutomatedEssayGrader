{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Import other functions\n",
    "from process.averageWordLength import averageWordLength\n",
    "from process.misspellings import nmisspelled\n",
    "from process.wordcount import length\n",
    "from process.averageSentenceLength import averageSentenceLength\n",
    "from process.grammarchecker import grammarCheck\n",
    "from process.keywords import keyWords\n",
    "from process.sentcount import sentcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'cleaned_essay',\n",
       "       'cleaned_essay_no_sw'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_feather('~/Documents/GitHub/AutomatedEssayGrader/essaygrader/data/essays.feather')\n",
    "df = df.drop('Average Word Length', axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean essays\n",
    "df = pd.read_feather('data/essays.feather')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['cleaned_essay'] = df['essay'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing filler words\n",
    "def filler(word):\n",
    "    if (word.isupper() == True) and (any([char.isdigit() for char in word])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df['cleaned_essay2'] = df['cleaned_essay'].apply(lambda i : [x for x in i if not filler(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('~/Documents/GitHub/AutomatedEssayGrader/essaygrader/data/essays.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        [Dear, local, newspaper, think, effects, compu...\n",
       "1        [Dear, believe, using, computers, benefit, us,...\n",
       "2        [Dear, people, use, computers, everyone, agree...\n",
       "3        [Dear, Local, Newspaper, found, many, experts,...\n",
       "4        [Dear, know, computers, positive, effect, peop...\n",
       "                               ...                        \n",
       "12971    [stories, mothers, daughters, either, enemies,...\n",
       "12972    [never, understood, meaning, laughter, shortes...\n",
       "12973    [laugh, habit, cause, causes, laughing, even, ...\n",
       "12974    [Trippin, fences, years, young, short, years, ...\n",
       "12975    [Many, people, believe, laughter, improve, lif...\n",
       "Name: cleaned_essay2_no_sw, Length: 12976, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['cleaned_essay2_no_sw'] = df['cleaned_essay2'].apply(lambda x : [w for w in x if not w.lower() in stop_words])\n",
    "\n",
    "df['cleaned_essay2_no_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new features\n",
    "df['Average Word Length'] = df['cleaned_essay2'].apply(averageWordLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['misspelled'] = df['cleaned_essay2'].swifter.apply(nmisspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(essay):\n",
    "    return len(essay)\n",
    "df['word_count'] = df['cleaned_essay2'].apply(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_sentence_length'] = df['essay'].apply(averageSentenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grammar_errors'] = df['essay'].apply(grammarCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['key_words_count'] = df['cleaned_essay2'].apply(keyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentcount'] = df['essay'].apply(sentcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To feather\n",
    "df.to_feather('data/essaysPrelim.feather')"
   ]
  }
 ]
}